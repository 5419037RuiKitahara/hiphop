{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-xnd-lSWgZF"
      },
      "outputs": [],
      "source": [
        "#@title Google driveをマウント\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用するドラム音源のパスとファイル名にあるドラム音源のテンポを入力しましょう。"
      ],
      "metadata": {
        "id": "p2t9ruphW80e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename_b = \"\" # @param {type:\"string\"}\n",
        "tempo_b =  0 #@param {type:\"integer\"}\n",
        "print(filename_b)"
      ],
      "metadata": {
        "id": "kQ2EDXmfWvLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "歌唱を含む曲のパスを入力しましょう。"
      ],
      "metadata": {
        "id": "fFaOeCJnXCNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install pydub\n",
        "import pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "#曲のパスを指定\n",
        "filename = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#outname=パスのファイル名\n",
        "outname = os.path.basename(filename)\n",
        "outname = outname.replace(\".mp3\",\"\")\n",
        "outname = outname.replace(\".wav\",\"\")\n",
        "\n",
        "#ファイル名のwavファイルを作成\n",
        "if '.mp3' in filename:\n",
        "  sound = pydub.AudioSegment.from_mp3(filename)\n",
        "  sound.export(outname+\".wav\", format=\"wav\")\n",
        "if '.wav' in filename:\n",
        "  sound = pydub.AudioSegment.from_wav(filename)\n",
        "  sound.export(outname+\".wav\", format=\"wav\")\n",
        "filename = outname+\".wav\"\n",
        "filename_s =filename\n",
        "print(filename)\n",
        "print(outname)"
      ],
      "metadata": {
        "id": "2NDpzK-lW4GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "os.path.basename()関数で、ファイル名のみを補完します。\n",
        "\n",
        "outname.replace()関数で、.mp3、.wavを削除したファイル名を補完します。\n",
        "pydub.AudioSegment.from_mp3()関数、pydub.AudioSegment.from_wav()関数で音声データを読み込み、export()関数で\"ファイル名.wav\"のシンプルなwavファイルを作成します。これで長いパス名を省略します。"
      ],
      "metadata": {
        "id": "5kdtQrOwZsct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 編曲したい曲のテンポを推定\n",
        "\n",
        "librosaを用いて、テンポ、ビート時刻の推定を行います。"
      ],
      "metadata": {
        "id": "C82OVcJ4XLCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "def tempo_estimate(filename):\n",
        "  y, sr = librosa.load(filename)\n",
        "  tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
        "  return tempo"
      ],
      "metadata": {
        "id": "zOyhlHNIXRdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beat_estimate(filename):\n",
        "  y, sr = librosa.load(filename)\n",
        "  tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
        "  beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
        "  return beat_times"
      ],
      "metadata": {
        "id": "9waohOCVXV8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "この時、次の音源分離の際に普通の音源ファイル名のままだとエラーが発生するため、原曲の最初のビート時刻から始まる「new.wav」を作ります。"
      ],
      "metadata": {
        "id": "MPYL0fZfZhqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tempo = tempo_estimate(filename)\n",
        "beat_times = beat_estimate(filename_s)\n",
        "if tempo>170:\n",
        "  tempo =tempo/2\n",
        "sound = AudioSegment.from_file(filename)\n",
        "sound1 = sound[beat_times[0]:]\n",
        "sound1.export(\"new.wav\", format=\"wav\")\n",
        "filename = \"new.wav\"\n",
        "print(tempo)"
      ],
      "metadata": {
        "id": "swoG1iY6XbKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 歌唱部分の抽出\n",
        "Spleeterを用いて音源抽出を行います。"
      ],
      "metadata": {
        "id": "hPj55IgYZeBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spleeter\n",
        "\n",
        "def sound_separation(filename):\n",
        "  #Spleeterを使用し歌声部分とその他を分離\n",
        "  !spleeter separate -h\n",
        "  !spleeter separate -o output/ {filename}"
      ],
      "metadata": {
        "id": "0lleKTaIXgVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このままだとファイル名がnewのままなので名前を変えます。"
      ],
      "metadata": {
        "id": "Pqd1w2RDZapg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sound_separation(\"new.wav\")\n",
        "os.rename(\"/content/output/new\", \"/content/output/\"+outname)"
      ],
      "metadata": {
        "id": "5vFa9EeOXjso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 歌唱の最初の位置を検出"
      ],
      "metadata": {
        "id": "qx5bLNfdZV6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inaSpeechSegmenter\n",
        "!pip install pydub\n",
        "from inaSpeechSegmenter import Segmenter\n",
        "\n",
        "def vocal_detection(filename):\n",
        "  seg = Segmenter(vad_engine='smn', detect_gender=False)\n",
        "  # 区間検出実行（たったこれだけでOK）\n",
        "  segmentation = seg(filename)\n",
        "  speech_segment_index = 0\n",
        "  start_time = 0\n",
        "  for segment in segmentation:\n",
        "    segment_label = segment[0]\n",
        "    i = 0\n",
        "    if (segment_label == 'speech'):  # 音声区間\n",
        "        start_time = segment[1] * 1000\n",
        "        print(start_time)\n",
        "        break\n",
        "  return start_time"
      ],
      "metadata": {
        "id": "A8dcYXfAXn50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "音声区間検出ライブラリinaSpeechSegmenterを用いて音声区間の最初の位置を検出します。"
      ],
      "metadata": {
        "id": "x3914PUVZRl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = vocal_detection(\"/content/output/\"+outname+\"/vocals.wav\")"
      ],
      "metadata": {
        "id": "wZndx8y0Xsa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 歌唱直前のビート時刻を計測し、分割\n",
        "beat_framesをlibrosa.frames_to_time()関数で時間に直します。"
      ],
      "metadata": {
        "id": "jEiyV3vKZOPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#歌声直前のビート時刻計測\n",
        "beat_times = beat_estimate(filename_s)\n",
        "beat_start = 0\n",
        "i = 0\n",
        "for b in beat_times:\n",
        "  b = beat_times*1000\n",
        "  if b[0] > start:\n",
        "    beat_start = b[0]\n",
        "  if b[i]<=start :\n",
        "    beat_start = b[i]\n",
        "  i+=1\n",
        "print(beat_start)\n",
        "\n",
        "# 歌声の直前までの無音を消去\n",
        "\n",
        "\n",
        "sound = AudioSegment.from_file(voice_name)\n",
        "sound1 = sound[beat_start:] #歌声部分[開始,終了]\n",
        "sound1.export(\"voice1.wav\", format=\"wav\")\n",
        "voice_name_c=\"voice1.wav\""
      ],
      "metadata": {
        "id": "zYXmGH0rXyG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ビート時刻から歌声直前のビート時刻を探し、歌唱をその位置から開始するようにします。"
      ],
      "metadata": {
        "id": "M-_Y5TgGZIni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## テンポを変更"
      ],
      "metadata": {
        "id": "JCdL7VgUYIgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "\n",
        "def tempo_change(filename):\n",
        "  y, sr = librosa.load(filename)\n",
        "  tempo=tempo_estimate(filename_s)\n",
        "  y_new  = librosa.effects.time_stretch(y, rate=tempo_b/tempo)\n",
        "  sf.write(\"tc.wav\", y_new, sr, subtype=\"PCM_24\")"
      ],
      "metadata": {
        "id": "eql8mO-jX2ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ドラムの前に無音区間を追加"
      ],
      "metadata": {
        "id": "JoeQ4T5jYCqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ドラムパターンに無音部分を追加\n",
        "def silent_plus(duration,filename):\n",
        "  a = AudioSegment.silent(duration=duration)\n",
        "  b = AudioSegment.from_file(filename)\n",
        "  b = b*30\n",
        "  c = a + b\n",
        "  c.export(\"drum.wav\",format=\"wav\")"
      ],
      "metadata": {
        "id": "JICQ78llX47W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ドラムと歌唱を合成"
      ],
      "metadata": {
        "id": "nL0RvVZKWmiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silent_plus(0,filename_b)\n",
        "# 歌唱とドラムを合成\n",
        "sound1 = AudioSegment.from_file(\"drum.wav\") #ドラム\n",
        "sound2 = AudioSegment.from_file(\"tc.wav\")#歌声\n",
        "output_last =sound1.overlay(sound2,position=0)\n",
        "# save the result\n",
        "output_last.export(outname+\"_mixed.wav\", format=\"wav\")"
      ],
      "metadata": {
        "id": "xf20dPXlX7Yd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}